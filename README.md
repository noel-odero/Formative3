# Formative 3 â€“ Probability Distributions, Bayesian Probability, and Gradient Descent

**Group Members:** Angie Noel, Modestine Nformi, Sharif Kiviiri, Josephine Kanu


This repository contains implementations for four different analytical tasks:
1) working with a **bivariate normal distribution** and visualising probability densities,
2) applying **Bayesâ€™ Theorem**,
3) implementing **Gradient Descent for Multiple Variables**.
4) Code version of the **Gradient Descent**

Each part is self-contained in its own folder.



## Repository Structure


```
.
â”œâ”€â”€ part1/   # Bivariate normal distribution analysis & plots
â”œâ”€â”€ part2/   # Bayesâ€™ Theorem implementation 
â”œâ”€â”€ part3/   # Gradient Descent implementation
â”œâ”€â”€ part4/   # Gradient Descent implementation (vectorised)
â””â”€â”€ README.md
```


## Part 1: Bivariate Normal Distribution

- We defined a bivariate normal PDF with means, variances and correlation.
- We generated a probability density surface and contour plots.
- We demonstrated how different correlation values affect the joint PDF shape.

Plots generated in this section:

 ![alt text](image-1.png) 


 ![Contour Plane](image.png) 


---

## Part 2: Bayesâ€™ Probability

Implementation of Bayesâ€™ Theorem and demonstration with example values.

We showed how posterior probability changes based on prior + evidence likelihood and illustrated the difference between P(A|B) and P(B|A).

This implementation shows how Bayesâ€™ Theorem bridges statistics and natural language processing (NLP).
By quantifying the relationship between keywords and sentiment, we gain interpretable, data-driven insights into how language patterns reflect human opinions

image generated by this section are


 ![posterior probalility p(positive/keyword)](./image3%20probability.png)

The image above shows the posterior probabilities 
ğ‘ƒ
(
Positive
âˆ£
keyword
)
P(Positiveâˆ£keyword) for each keyword.
Each bar represents how strongly a word predicts a positive review.



---

## Part 4: Gradient Descent for Multiple Variables

- We implemented multivariate linear regression using **vectorized gradient descent**.
- We ran 4 iterations to illustrate update steps.
- Then we used SciPy to verify correctness.

---

## Requirements

pip install numpy pandas matplotlib scipy scikit-learn


---

## How to Run

Each part has a Python file, run them independently:

cd part1 && python main.py
cd part2 && python main.py
cd part3 && python main.py